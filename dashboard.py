import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta
import os
from dotenv import load_dotenv

# -----------------------------------------------------------------------------
# 1. í™˜ê²½ ì„¤ì • ë° ë¹„ë°€í‚¤ ê´€ë¦¬ (Secret Management)
# -----------------------------------------------------------------------------
st.set_page_config(
    page_title="Farminfo Analytics",
    page_icon="ğŸŠ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ë¹„ë°€í‚¤ ë¡œë“œ í•¨ìˆ˜ (Local vs Cloud Hybrid)
def get_naver_api_secrets():
    """
    Naver API í‚¤ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
    1ìˆœìœ„: Streamlit Cloud Secrets (st.secrets)
    2ìˆœìœ„: ë¡œì»¬ .env íŒŒì¼
    """
    # 1. Streamlit Cloud Secrets í™•ì¸
    # 1. Streamlit Cloud Secrets í™•ì¸
    try:
        if "naver_api" in st.secrets:
            return st.secrets["naver_api"]["client_id"], st.secrets["naver_api"]["client_secret"]
    except FileNotFoundError:
        pass # secrets.tomlì´ ì—†ëŠ” ê²½ìš° ë¬´ì‹œí•˜ê³  ë¡œì»¬ .env ì‹œë„
    except Exception:
        pass # ê¸°íƒ€ ì—ëŸ¬ ë¬´ì‹œ
    
    # 2. ë¡œì»¬ .env í™•ì¸
    current_dir = os.path.dirname(os.path.abspath(__file__))
    project_root = os.path.dirname(current_dir)
    
    # .env í›„ë³´ ê²½ë¡œ
    env_candidates = [
        os.path.join(project_root, ".env"),
        os.path.join(os.getcwd(), ".env")
    ]
    
    for env_path in env_candidates:
        if os.path.exists(env_path):
            load_dotenv(env_path)
            break
            
    c_id = os.getenv('NAVER_CLIENT_ID')
    c_secret = os.getenv('NAVER_CLIENT_SECRET')
    
    if c_id and c_secret:
        return c_id, c_secret
    
    return None, None

client_id, client_secret = get_naver_api_secrets()

# -----------------------------------------------------------------------------
# 2. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ (Data Loading)
# -----------------------------------------------------------------------------
@st.cache_data
def load_data():
    """ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  ìºì‹±í•©ë‹ˆë‹¤."""
    # íŒŒì¼ ê²½ë¡œ (ì ˆëŒ€ ê²½ë¡œ ë˜ëŠ” ìƒëŒ€ ê²½ë¡œ)
    # ---------------------------
    # [Path Debugging Strategy]
    # ---------------------------
    # Streamlit Cloudì™€ ë¡œì»¬ í™˜ê²½ì˜ ê²½ë¡œ ì°¨ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ í›„ë³´êµ° íƒìƒ‰
    current_dir = os.path.dirname(os.path.abspath(__file__)) # .../output
    project_root = os.path.dirname(current_dir)             # .../farminfo
    
    candidate_paths = [
        # 1. ìŠ¤í¬ë¦½íŠ¸ ê¸°ì¤€ ìƒëŒ€ ê²½ë¡œ (ë¡œì»¬/Cloud ì¼ë°˜ì )
        os.path.join(project_root, "input", "preprocessed_data.csv"),
        # 2. í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬(CWD) ê¸°ì¤€ ì…ìˆ˜ (Streamlit Cloud Root ì‹¤í–‰ ì‹œ)
        os.path.join(os.getcwd(), "input", "preprocessed_data.csv"),
        # 3. Mount ê²½ë¡œ í•˜ë“œì½”ë”© (ìµœí›„ì˜ ìˆ˜ë‹¨, ë¦¬í¬ì§€í† ë¦¬ëª…ì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ)
        "/mount/src/farminfo/input/preprocessed_data.csv", 
        "input/preprocessed_data.csv"
    ]
    
    filepath = None
    for path in candidate_paths:
        if os.path.exists(path):
            filepath = path
            break
            
    if filepath is None:
        st.error("ğŸš¨ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        st.write("### Debug Info")
        st.write(f"- Current Working Dir: `{os.getcwd()}`")
        st.write(f"- Script Loc: `{current_dir}`")
        st.write("#### Checked Paths:")
        for p in candidate_paths:
            st.write(f"- `{p}`")
            
        # ë””ë ‰í† ë¦¬ êµ¬ì¡° íŒíŠ¸ ì œê³µ
        st.write("#### Directory Structure (Root):")
        try:
            st.write(os.listdir(os.getcwd()))
            if os.path.exists("input"):
                 st.write(f"input dir contents: {os.listdir('input')}")
        except Exception as e:
            st.write(f"Error listing dir: {e}")
            
        return pd.DataFrame()

    df = pd.read_csv(filepath)
    
    # ë‚ ì§œ ë³€í™˜
    if 'ì£¼ë¬¸ì¼' in df.columns:
        df['ì£¼ë¬¸ì¼'] = pd.to_datetime(df['ì£¼ë¬¸ì¼'])
        df['ì£¼ë¬¸ì›”'] = df['ì£¼ë¬¸ì¼'].dt.to_period('M').astype(str)
        df['ì£¼ë¬¸ì‹œê°„'] = df['ì£¼ë¬¸ì¼'].dt.hour
        df['ìš”ì¼'] = df['ì£¼ë¬¸ì¼'].dt.day_name()
    
    # [Simulation] ì—°ë ¹ëŒ€ ë°ì´í„° ìƒì„± (ë°ëª¨ìš©)
    if 'ì—°ë ¹ëŒ€' not in df.columns:
        import numpy as np
        # ì¬í˜„ì„±ì„ ìœ„í•´ ì‹œë“œ ê³ ì •
        np.random.seed(42)
        age_groups = ['20ëŒ€', '30ëŒ€', '40ëŒ€', '50ëŒ€', '60ëŒ€ ì´ìƒ']
        # ê°€ì¤‘ì¹˜: 3040 ì£¼ì¶•
        probs = [0.15, 0.30, 0.35, 0.15, 0.05] 
        df['ì—°ë ¹ëŒ€'] = np.random.choice(age_groups, size=len(df), p=probs)
    
    # ìˆ«ìí˜• ì»¬ëŸ¼ ë³€í™˜ (ì½¤ë§ˆ ì œê±°)
    numeric_cols = ['ê²°ì œê¸ˆì•¡', 'íŒë§¤ë‹¨ê°€', 'ê³µê¸‰ë‹¨ê°€', 'ì£¼ë¬¸ì·¨ì†Œ ê¸ˆì•¡', 'ì‹¤ê²°ì œ ê¸ˆì•¡', 'ì£¼ë¬¸ìˆ˜ëŸ‰']
    for col in numeric_cols:
        if col in df.columns and df[col].dtype == object:
            df[col] = df[col].astype(str).str.replace(',', '').astype(float)
    
    # ë§ˆì§„ ê³„ì‚°
    if 'íŒë§¤ë‹¨ê°€' in df.columns and 'ê³µê¸‰ë‹¨ê°€' in df.columns:
        df['ë§ˆì§„'] = (df['íŒë§¤ë‹¨ê°€'] - df['ê³µê¸‰ë‹¨ê°€']) * df.get('ì£¼ë¬¸ìˆ˜ëŸ‰', 1)
        
    return df

raw_df = load_data()

if raw_df.empty:
    st.stop()

# -----------------------------------------------------------------------------
# 3. ì‚¬ì´ë“œë°” ë° í”„ë¡¬í”„íŠ¸ (Sidebar & Prompt UI)
# -----------------------------------------------------------------------------
with st.sidebar:
    st.title("ğŸ›ï¸ ì»¨íŠ¸ë¡¤ íŒ¨ë„")
    
    # ê¸°ê°„ ì„¤ì •
    min_date = raw_df['ì£¼ë¬¸ì¼'].min().date()
    max_date = raw_df['ì£¼ë¬¸ì¼'].max().date()
    
    date_range = st.date_input(
        "ê¸°ê°„ ì„ íƒ",
        value=(min_date, max_date),
        min_value=min_date,
        max_value=max_date
    )
    
    # ë¹ ë¥¸ í•„í„°
    st.divider()
    all_channels = raw_df['ì£¼ë¬¸ê²½ë¡œ'].unique().tolist()
    selected_channels = st.multiselect("ì£¼ë¬¸ ê²½ë¡œ í•„í„°", all_channels, default=all_channels)
    
    if 'ì´ë²¤íŠ¸ ì—¬ë¶€' in raw_df.columns:
        show_event_only = st.checkbox("ì´ë²¤íŠ¸ ì£¼ë¬¸ë§Œ ë³´ê¸°")
    else:
        show_event_only = False
        
    st.info(f"Updated: {pd.Timestamp.now().strftime('%Y-%m-%d')}")
    
    # API ìƒíƒœ í‘œì‹œ (ë³´ì•ˆìƒ í‚¤ ìì²´ëŠ” ë…¸ì¶œ X)
    if client_id:
        st.success("Naver API Key Loaded âœ…")
    else:
        st.warning("Naver API Key Not Found âš ï¸")

# ë©”ì¸ í”„ë¡¬í”„íŠ¸ ì˜ì—­
st.markdown("## ğŸŠ Farminfo Prompt Analytics")
prompt = st.text_input(
    "ë¶„ì„í•˜ê³  ì‹¶ì€ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ì„œìš¸, ê°ê·¤, ì„ ë¬¼, ì¹´ì¹´ì˜¤í†¡)", 
    placeholder="í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ë©´ ê´€ë ¨ ë°ì´í„°ë§Œ í•„í„°ë§í•˜ì—¬ ê¹Šì´ ìˆê²Œ ë¶„ì„í•©ë‹ˆë‹¤.",
    help="ìƒí’ˆëª…, ì˜µì…˜, ì£¼ì†Œ, ì£¼ë¬¸ê²½ë¡œ ë“±ì—ì„œ í‚¤ì›Œë“œë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤."
)

# -----------------------------------------------------------------------------
# 4. ë°ì´í„° í•„í„°ë§ ë¡œì§ (Filtering Logic)
# -----------------------------------------------------------------------------
df_filtered = raw_df.copy()

# 1. ê¸°ê°„ í•„í„°
if len(date_range) == 2:
    start_date, end_date = date_range
    df_filtered = df_filtered[
        (df_filtered['ì£¼ë¬¸ì¼'].dt.date >= start_date) & 
        (df_filtered['ì£¼ë¬¸ì¼'].dt.date <= end_date)
    ]

# 2. ì±„ë„ í•„í„°
if selected_channels:
    df_filtered = df_filtered[df_filtered['ì£¼ë¬¸ê²½ë¡œ'].isin(selected_channels)]

# 3. ì´ë²¤íŠ¸ í•„í„°
if show_event_only and 'ì´ë²¤íŠ¸ ì—¬ë¶€' in df_filtered.columns:
    df_filtered = df_filtered[df_filtered['ì´ë²¤íŠ¸ ì—¬ë¶€'] == 'Y']

# 4. í”„ë¡¬í”„íŠ¸(ê²€ìƒ‰ì–´) í•„í„° - í•µì‹¬ ë¡œì§
if prompt:
    with st.spinner(f"'{prompt}' ê´€ë ¨ ë°ì´í„° ë¶„ì„ ì¤‘..."):
        # ê²€ìƒ‰ ëŒ€ìƒ ì»¬ëŸ¼
        search_cols = ['ìƒí’ˆëª…', 'ì˜µì…˜ì½”ë“œ', 'ì£¼ì†Œ', 'ì£¼ë¬¸ê²½ë¡œ', 'ëª©ì ', 'ê³ ê°ì„ íƒì˜µì…˜']
        valid_cols = [c for c in search_cols if c in df_filtered.columns]
        
        # í‚¤ì›Œë“œ í¬í•¨ ì—¬ë¶€ ë§ˆìŠ¤í¬ ìƒì„± (OR ì¡°ê±´)
        mask = pd.Series(False, index=df_filtered.index)
        for col in valid_cols:
            mask |= df_filtered[col].astype(str).str.contains(prompt, case=False)
        
        df_filtered = df_filtered[mask]
        
        if df_filtered.empty:
            st.warning(f"'{prompt}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            st.stop()
        else:
            st.success(f"'{prompt}' í‚¤ì›Œë“œë¡œ {len(df_filtered):,}ê±´ì˜ ë°ì´í„°ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")

# -----------------------------------------------------------------------------
# 5. KPI ë©”íŠ¸ë¦­ (Metrics) [Table Like 1]
# -----------------------------------------------------------------------------
total_sales = df_filtered['ì‹¤ê²°ì œ ê¸ˆì•¡'].sum()
total_orders = len(df_filtered)
avg_order_value = total_sales / total_orders if total_orders > 0 else 0
avg_margin = df_filtered['ë§ˆì§„'].mean() if 'ë§ˆì§„' in df_filtered.columns else 0

col1, col2, col3, col4 = st.columns(4)
col1.metric("ì´ ë§¤ì¶œì•¡", f"{total_sales:,.0f}ì›")
col2.metric("ì´ ì£¼ë¬¸ìˆ˜", f"{total_orders:,}ê±´")
col3.metric("í‰ê·  ê°ë‹¨ê°€ (AOV)", f"{avg_order_value:,.0f}ì›")
col4.metric("í‰ê·  ë§ˆì§„", f"{avg_margin:,.0f}ì›")

st.divider()

# -----------------------------------------------------------------------------
# 5. ë©”ì¸ ëŒ€ì‹œë³´ë“œ êµ¬ì¡° (Sidebar Navigation)
# -----------------------------------------------------------------------------

# ì‚¬ì´ë“œë°” ë©”ë‰´ êµ¬ì„±
st.sidebar.header("Navigation")
menu = st.sidebar.radio(
    "ë¶„ì„ ë©”ë‰´ ì„ íƒ",
    [
        "ğŸ“Š ë§¤ì¶œ ë° ì„±ê³¼ (Sales)",
        "ğŸŠ ìƒí’ˆ ë¶„ì„ (Product)",
        "ğŸ“¢ ì±„ë„ ë° ì§€ì—­ (Ch & Reg)",
        "ğŸ‘¥ ê³ ê° ë¶„ì„ (Customer)",
        "ğŸ“ˆ ì…€ëŸ¬ ë¶„ì„ (Seller)"
    ]
)

st.title(f"{menu}")
st.markdown("---")

# -----------------------------------------------------------
# View 1: ğŸ“Š ë§¤ì¶œ ë° ì„±ê³¼ Analysis
# -----------------------------------------------------------
if "ë§¤ì¶œ" in menu:
    # [View 1] ğŸ“Š ë§¤ì¶œ ë° ì„±ê³¼ Analysis
    
    # [Row 1] KPI ì§€í‘œ
    total_sales = df_filtered['ì‹¤ê²°ì œ ê¸ˆì•¡'].sum()
    total_orders = df_filtered['ì£¼ë¬¸ìˆ˜ëŸ‰'].sum()
    unique_customers = df_filtered['ì£¼ë¬¸ìëª…'].nunique()
    
    col_kpi1, col_kpi2, col_kpi3 = st.columns(3)
    col_kpi1.metric("ì´ ë§¤ì¶œì•¡", f"{total_sales:,.0f} ì›")
    col_kpi2.metric("ì´ ì£¼ë¬¸ìˆ˜ëŸ‰", f"{total_orders:,.0f} ê°œ")
    col_kpi3.metric("ìˆœìˆ˜ êµ¬ë§¤ì ìˆ˜", f"{unique_customers:,.0f} ëª…")
    
    st.divider()

    # [ìˆ˜ìµí™” ì œì•ˆ] ëª©í‘œ ê°ë‹¨ê°€ (Target AOV) Analysis
    st.subheader("ğŸ’¡ ìˆ˜ìµí™” ì œì•ˆ: ëª©í‘œ ê°ë‹¨ê°€ (Target AOV)")
    
    # ë§ˆì§„ ë°ì´í„° ê°€ìš©ì„± í™•ì¸
    has_margin = 'ë§ˆì§„' in df_filtered.columns
    
    if has_margin and not df_filtered.empty:
        # ìƒìœ„ 25% ê³ ë§ˆì§„ ì£¼ë¬¸ ê¸°ì¤€
        threshold = df_filtered['ë§ˆì§„'].quantile(0.75)
        high_margin_orders = df_filtered[df_filtered['ë§ˆì§„'] >= threshold]
        
        if not high_margin_orders.empty:
            current_aov = total_sales / total_orders if total_orders > 0 else 0
            target_aov = high_margin_orders['ì‹¤ê²°ì œ ê¸ˆì•¡'].mean()
            
            # ëª©í‘œê°€ í˜„ì¬ë³´ë‹¤ ë‚®ìœ¼ë©´ (ê³ ë§ˆì§„ ìƒí’ˆì´ ì €ê°€ì¼ ê²½ìš°) ìƒìœ„ 10% ë§¤ì¶œ ì£¼ë¬¸ìœ¼ë¡œ ëŒ€ì²´ ë¡œì§
            if target_aov <= current_aov:
                 target_aov = df_filtered['ì‹¤ê²°ì œ ê¸ˆì•¡'].quantile(0.90) # ìƒìœ„ 10% ê¸ˆì•¡ ê¸°ì¤€

            upside_potential = (target_aov - current_aov) * total_orders
            
            p_col1, p_col2 = st.columns([1, 2])
            
            with p_col1:
                st.metric(
                    label="ëª©í‘œ ê°ë‹¨ê°€ (Target AOV)", 
                    value=f"{target_aov:,.0f} ì›", 
                    delta=f"+{target_aov - current_aov:,.0f} ì›",
                    help="ìƒìœ„ 25% ê³ ë§ˆì§„ ì£¼ë¬¸ë“¤ì˜ í‰ê·  ê°ë‹¨ê°€ì…ë‹ˆë‹¤."
                )
                st.caption(f"í˜„ì¬ AOV: {current_aov:,.0f} ì›")
                
            with p_col2:
                st.info(f"""
                **ğŸ’° ìˆ˜ìµ ê·¹ëŒ€í™” ì „ëµ**
                
                ê°ë‹¨ê°€ë¥¼ **{target_aov:,.0f}ì›**ìœ¼ë¡œ ë†’ì¸ë‹¤ë©´, 
                ì´ ë§¤ì¶œì´ ì•½ **{upside_potential:,.0f}ì›** ì¦ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
                
                **ì¶”ì²œ ì•¡ì…˜:**
                - {target_aov:,.0f}ì› ì´ìƒ êµ¬ë§¤ ì‹œ **ë¬´ë£Œ ë°°ì†¡** ë˜ëŠ” **ì‚¬ì€í’ˆ** ì¦ì •
                - **ì„¸íŠ¸ ìƒí’ˆ(ë²ˆë“¤)** êµ¬ì„±ì„ í†µí•´ ì£¼ë¬¸ ê¸ˆì•¡ ìƒí–¥ ìœ ë„
                - ì¥ë°”êµ¬ë‹ˆ í˜ì´ì§€ì—ì„œ **ì¶”ê°€ ì˜µì…˜(Cross-sell)** ë…¸ì¶œ ê°•í™”
                """)
                
            # [Bundle Proposal]
            st.markdown("#### ğŸ ì¶”ì²œ ìƒí’ˆ êµ¬ì„± (Golden Bundle)")
            
            # 1. Anchor Product (ê°€ì¥ ë§ì´ íŒ”ë¦° ìƒí’ˆ)
            top_anchor = df_filtered.groupby('ìƒí’ˆëª…').agg({'ì£¼ë¬¸ìˆ˜ëŸ‰':'sum', 'ì‹¤ê²°ì œ ê¸ˆì•¡':'mean', 'ë§ˆì§„':'mean'}).reset_index()
            anchor_row = top_anchor.sort_values('ì£¼ë¬¸ìˆ˜ëŸ‰', ascending=False).iloc[0]
            anchor_name = anchor_row['ìƒí’ˆëª…']
            anchor_price = anchor_row['ì‹¤ê²°ì œ ê¸ˆì•¡']
            
            # 2. Add-on Product (Target AOVë¥¼ ë§ì¶”ê¸° ìœ„í•œ ê³ ë§ˆì§„ ìƒí’ˆ)
            gap_to_target = max(0, target_aov - anchor_price)
            
            # í›„ë³´êµ°: Anchorê°€ ì•„ë‹ˆë©´ì„œ, í‰ê·  ê°€ê²©ì´ Gap ì´ìƒì¸ ìƒí’ˆ ì¤‘ ë§ˆì§„ì´ ê°€ì¥ ë†’ì€ ê²ƒ
            candidates = top_anchor[top_anchor['ìƒí’ˆëª…'] != anchor_name]
            addon_candidates = candidates[candidates['ì‹¤ê²°ì œ ê¸ˆì•¡'] >= gap_to_target * 0.8] # ê°­ì˜ 80% ì´ìƒ ì»¤ë²„ ê°€ëŠ¥í•œ ìƒí’ˆ
            
            if not addon_candidates.empty:
                addon_row = addon_candidates.sort_values('ë§ˆì§„', ascending=False).iloc[0]
                addon_name = addon_row['ìƒí’ˆëª…']
                addon_price = addon_row['ì‹¤ê²°ì œ ê¸ˆì•¡']
                bundle_price = anchor_price + addon_price
                
                # [Targeting Analysis]
                # ì œì•ˆëœ ë‘ ìƒí’ˆ(Anchor, Add-on)ì„ êµ¬ë§¤í•œ ì´ë ¥ ë¶„ì„
                target_products = [anchor_name, addon_name]
                target_df = df_filtered[df_filtered['ìƒí’ˆëª…'].isin(target_products)]
                
                if not target_df.empty:
                    # 1. Top Region
                    if 'ê´‘ì—­ì§€ì—­' in target_df.columns:
                        top_region = target_df['ê´‘ì—­ì§€ì—­'].value_counts().idxmax()
                    else:
                        top_region = "ì „êµ­"
                        
                    # 2. Top Age Group
                    if 'ì—°ë ¹ëŒ€' in target_df.columns:
                        top_age = target_df['ì—°ë ¹ëŒ€'].value_counts().idxmax()
                    else:
                        top_age = "ì „ ì—°ë ¹"
                        
                    targeting_info = f"\n\n**ğŸ¯ íƒ€ê²Ÿ ë§ˆì¼€íŒ… (Target Audience):**\n- **ì¶”ì²œ ì§€ì—­:** {top_region}\n- **í•µì‹¬ ì—°ë ¹:** {top_age} ê³ ê°ì¸µ"
                else:
                    targeting_info = ""

                st.success(f"""
                **ì¶”ì²œ ë²ˆë“¤: {anchor_name} + {addon_name}**
                
                - **êµ¬ì„±:** {anchor_name} ({anchor_price:,.0f}ì›) + {addon_name} ({addon_price:,.0f}ì›)
                - **ë²ˆë“¤ ê°€ê²©:** {bundle_price:,.0f}ì› (ëª©í‘œ ê°ë‹¨ê°€ {target_aov:,.0f}ì› ìƒíšŒ ğŸš€)
                - **ê¸°ëŒ€ íš¨ê³¼:** ê³ ê°ì´ ê°€ì¥ ì„ í˜¸í•˜ëŠ” ìƒí’ˆì— ê³ ë§ˆì§„ ìƒí’ˆì„ ì œì•ˆí•˜ì—¬ ê°ë‹¨ê°€ì™€ ì´ìµ ë™ë°˜ ìƒìŠ¹
                {targeting_info}
                """)
            else:
                st.write("Target AOVë¥¼ ë‹¬ì„±í•  ì ì ˆí•œ ì¶”ê°€ ìƒí’ˆì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

        else:
            st.info("ê³ ë§ˆì§„ ì£¼ë¬¸ ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•Šì•„ ëª©í‘œë¥¼ ì‚°ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.warning("ë§ˆì§„ ë°ì´í„°(ê³µê¸‰ë‹¨ê°€/íŒë§¤ë‹¨ê°€)ê°€ ì—†ì–´ ìˆ˜ìµì„± ë¶„ì„ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    st.divider()
    
    # [Graph 1] ì¼ë³„ ë§¤ì¶œ ì¶”ì´
    st.subheader("ğŸ“ˆ ì¼ë³„ ë§¤ì¶œ ë° ì£¼ë¬¸ ì¶”ì´")
    daily_sales = df_filtered.groupby('ì£¼ë¬¸ì¼').agg({'ì‹¤ê²°ì œ ê¸ˆì•¡':'sum', 'ì£¼ë¬¸ìˆ˜ëŸ‰':'sum'}).reset_index()
    
    fig_daily = px.line(daily_sales, x='ì£¼ë¬¸ì¼', y='ì‹¤ê²°ì œ ê¸ˆì•¡', title='ì¼ë³„ ë§¤ì¶œ ì¶”ì´')
    fig_daily.update_traces(line_color='#FF9F40', line_width=3)
    st.plotly_chart(fig_daily, use_container_width=True)

elif "ìƒí’ˆ" in menu:
    # [View 2] ğŸŠ ìƒí’ˆ ë¶„ì„ Analysis
    st.header("ğŸŠ ìƒí’ˆ ë¶„ì„ (Product Analysis)")
    
    col_prod1, col_prod2 = st.columns([1, 1])
    
    with col_prod1:
        st.subheader("ğŸ© ì¹´í…Œê³ ë¦¬ë³„ íŒë§¤ ë¹„ì¤‘")
        if 'í’ˆì¢…' in df_filtered.columns and 'ë¬´ê²Œ êµ¬ë¶„' in df_filtered.columns:
            fig_sun = px.sunburst(
                df_filtered, 
                path=['í’ˆì¢…', 'ë¬´ê²Œ êµ¬ë¶„'], 
                values='ì‹¤ê²°ì œ ê¸ˆì•¡',
                color='ì‹¤ê²°ì œ ê¸ˆì•¡',
                color_continuous_scale='Oranges'
            )
            st.plotly_chart(fig_sun, use_container_width=True)
        else:
            st.warning("í’ˆì¢…/ë¬´ê²Œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
    with col_prod2:
        st.subheader("ğŸ† ìƒí’ˆ íŒë§¤ ìˆœìœ„ (Top 10)")
        top_products = df_filtered.groupby('ìƒí’ˆëª…')['ì‹¤ê²°ì œ ê¸ˆì•¡'].sum().sort_values(ascending=False).head(10).reset_index()
        fig_bar = px.bar(top_products, x='ì‹¤ê²°ì œ ê¸ˆì•¡', y='ìƒí’ˆëª…', orientation='h', text_auto='.2s')
        fig_bar.update_layout(yaxis={'categoryorder':'total ascending'})
        fig_bar.update_traces(marker_color='#FF8C00')
        st.plotly_chart(fig_bar, use_container_width=True)

    st.divider()

    # [Advanced Product Analysis]
    st.subheader("ğŸ”¬ ì‹¬ì¸µ ìƒí’ˆ ë¶„ì„ (Advanced Product Analysis)")

    # Data Preparation per Product
    if not df_filtered.empty:
        prod_stats = df_filtered.groupby('ìƒí’ˆëª…').agg({
            'ì‹¤ê²°ì œ ê¸ˆì•¡': 'sum', 
            'ì£¼ë¬¸ìˆ˜ëŸ‰': 'sum',
            'ì£¼ë¬¸ìëª…': 'nunique' # Number of Buyers
        }).reset_index()
        
        # Calculate Margin if available
        if 'ë§ˆì§„' in df_filtered.columns:
            margin_sum = df_filtered.groupby('ìƒí’ˆëª…')['ë§ˆì§„'].sum().reset_index()
            prod_stats = prod_stats.merge(margin_sum, on='ìƒí’ˆëª…', how='left')
        else:
            prod_stats['ë§ˆì§„'] = 0
            
        # 1. ABC Analysis (Pareto)
        prod_stats = prod_stats.sort_values('ì‹¤ê²°ì œ ê¸ˆì•¡', ascending=False)
        prod_stats['Cumulative Sales'] = prod_stats['ì‹¤ê²°ì œ ê¸ˆì•¡'].cumsum()
        prod_stats['Cumulative Perc'] = prod_stats['Cumulative Sales'] / prod_stats['ì‹¤ê²°ì œ ê¸ˆì•¡'].sum()
        
        def assign_grade(row):
            if row['Cumulative Perc'] <= 0.8: return 'A (í•µì‹¬)'
            elif row['Cumulative Perc'] <= 0.95: return 'B (ì¼ë°˜)'
            else: return 'C (ë¶€ì§„)'
            
        prod_stats['Grade'] = prod_stats.apply(assign_grade, axis=1)
        
        # Summary of Grades
        grade_counts = prod_stats['Grade'].value_counts().sort_index()
        
        st.markdown("##### 1. ABC ë“±ê¸‰ ë¶„ì„ (Pareto Principle)")
        st.caption("ë§¤ì¶œ ê¸°ì—¬ë„ ìƒìœ„ 80%ë¥¼ Aë“±ê¸‰, ì°¨ìœ„ 15%ë¥¼ Bë“±ê¸‰, í•˜ìœ„ 5%ë¥¼ Cë“±ê¸‰ìœ¼ë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤.")
        
        col_abc1, col_abc2 = st.columns([1, 2])
        
        with col_abc1:
            st.write("**ë“±ê¸‰ë³„ ìƒí’ˆ ìˆ˜**")
            st.dataframe(grade_counts, use_container_width=True)
            
        with col_abc2:
            fig_pareto = px.bar(
                prod_stats.head(20), 
                x='ìƒí’ˆëª…', 
                y='ì‹¤ê²°ì œ ê¸ˆì•¡',
                color='Grade',
                title='Top 20 ìƒí’ˆ ë§¤ì¶œ ê¸°ì—¬ë„',
                color_discrete_map={'A (í•µì‹¬)': '#E74C3C', 'B (ì¼ë°˜)': '#F1C40F', 'C (ë¶€ì§„)': '#95A5A6'}
            )
            st.plotly_chart(fig_pareto, use_container_width=True)

        st.divider()
        
        # 2. Product Portfolio Map (Treemap)
        st.markdown("##### 2. ìƒí’ˆ í¬íŠ¸í´ë¦¬ì˜¤ ë§µ (Treemap)")
        st.caption("ê³„ì¸µ: ë“±ê¸‰ > ìƒí’ˆëª… | í¬ê¸°: ë§¤ì¶œì•¡ | ìƒ‰ìƒ: ë§ˆì§„ìœ¨ (ì´ˆë¡ìƒ‰=ê³ ìˆ˜ìµ, ë¶‰ì€ìƒ‰=ì €ìˆ˜ìµ)")
        
        # Treemap requires non-negative values for size. Filter out negative sales.
        tree_df = prod_stats[prod_stats['ì‹¤ê²°ì œ ê¸ˆì•¡'] > 0].copy()
        
        # Calculate Margin Rate for Color
        tree_df['ë§ˆì§„ìœ¨'] = (tree_df['ë§ˆì§„'] / tree_df['ì‹¤ê²°ì œ ê¸ˆì•¡']) * 100
        tree_df['ë§ˆì§„ìœ¨'] = tree_df['ë§ˆì§„ìœ¨'].fillna(0)
        
        # Format for Hover
        tree_df['ë§¤ì¶œì•¡_fmt'] = tree_df['ì‹¤ê²°ì œ ê¸ˆì•¡'].apply(lambda x: f"{x:,.0f}ì›")
        tree_df['ë§ˆì§„_fmt'] = tree_df['ë§ˆì§„'].apply(lambda x: f"{x:,.0f}ì›")
        tree_df['ë§ˆì§„ìœ¨_fmt'] = tree_df['ë§ˆì§„ìœ¨'].apply(lambda x: f"{x:.1f}%")
        tree_df['ì£¼ë¬¸ìˆ˜_fmt'] = tree_df['ì£¼ë¬¸ìˆ˜ëŸ‰'].apply(lambda x: f"{x:,.0f}ê°œ")

        fig_treemap = px.treemap(
            tree_df,
            path=[px.Constant("ì „ì²´ ìƒí’ˆ"), 'Grade', 'ìƒí’ˆëª…'],
            values='ì‹¤ê²°ì œ ê¸ˆì•¡',
            color='ë§ˆì§„ìœ¨',
            color_continuous_scale='RdYlGn',
            color_continuous_midpoint=tree_df['ë§ˆì§„ìœ¨'].median(), # ä¸­é–“ê°’ ê¸°ì¤€
            custom_data=['ë§¤ì¶œì•¡_fmt', 'ë§ˆì§„_fmt', 'ë§ˆì§„ìœ¨_fmt', 'ì£¼ë¬¸ìˆ˜_fmt'],
            title="ìƒí’ˆ ê³„ì¸µë³„ ë§¤ì¶œ ë° ìˆ˜ìµì„±(ë§ˆì§„ìœ¨) ë¶„ì„"
        )
        
        fig_treemap.update_traces(
            textinfo="label+value+percent entry",
            hovertemplate="<b>%{label}</b><br>ë§¤ì¶œ: %{customdata[0]}<br>ë§ˆì§„: %{customdata[1]}<br>ë§ˆì§„ìœ¨: %{customdata[2]}<br>ì£¼ë¬¸ìˆ˜: %{customdata[3]}"
        )
        st.plotly_chart(fig_treemap, use_container_width=True)
        
        # 3. Detailed Data Table
        st.markdown("##### 3. ìƒí’ˆë³„ ìƒì„¸ ì§€í‘œ")
        
        # Add basic formatting
        display_df = prod_stats.copy()
        display_df['ì‹¤ê²°ì œ ê¸ˆì•¡'] = display_df['ì‹¤ê²°ì œ ê¸ˆì•¡'].apply(lambda x: f"{x:,.0f}")
        display_df['ë§ˆì§„'] = display_df['ë§ˆì§„'].apply(lambda x: f"{x:,.0f}")
        
        st.dataframe(
            display_df[['Grade', 'ìƒí’ˆëª…', 'ì‹¤ê²°ì œ ê¸ˆì•¡', 'ì£¼ë¬¸ìˆ˜ëŸ‰', 'ì£¼ë¬¸ìëª…', 'ë§ˆì§„', 'Cumulative Perc']],
            use_container_width=True,
            hide_index=True
        )

    else:
        st.info("ë¶„ì„í•  ìƒí’ˆ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

elif "ì±„ë„" in menu:
    # [View 3] ğŸ“¢ ì±„ë„ ë° ì§€ì—­ Analysis
    st.header("ğŸ“¢ ì±„ë„ ë° ì§€ì—­ ë¶„ì„ (Channel & Region)")
    
    col_ch1, col_ch2 = st.columns(2)
    
    with col_ch1:
        st.subheader("ğŸ“¢ ì£¼ë¬¸ ê²½ë¡œ(ì±„ë„) íš¨ìœ¨")
        channel_perf = df_filtered.groupby('ì£¼ë¬¸ê²½ë¡œ')[['ì‹¤ê²°ì œ ê¸ˆì•¡', 'ì£¼ë¬¸ìˆ˜ëŸ‰']].sum().reset_index()
        fig_ch = px.bar(channel_perf, x='ì£¼ë¬¸ê²½ë¡œ', y='ì‹¤ê²°ì œ ê¸ˆì•¡', color='ì£¼ë¬¸ê²½ë¡œ', title="ì±„ë„ë³„ ë§¤ì¶œì•¡")
        st.plotly_chart(fig_ch, use_container_width=True)
        
    with col_ch2:
        st.subheader("ğŸ“ ì§€ì—­ë³„ ë§¤ì¶œ ê·œëª¨")
        if 'ê´‘ì—­ì§€ì—­' in df_filtered.columns:
            region_stats = df_filtered.groupby('ê´‘ì—­ì§€ì—­')['ì‹¤ê²°ì œ ê¸ˆì•¡'].sum().reset_index().sort_values('ì‹¤ê²°ì œ ê¸ˆì•¡', ascending=True)
            fig_bar_region = px.bar(
                region_stats,
                x='ì‹¤ê²°ì œ ê¸ˆì•¡',
                y='ê´‘ì—­ì§€ì—­',
                orientation='h',
                text_auto='.2s',
                title="ì§€ì—­ë³„ ë§¤ì¶œì•¡"
            )
            fig_bar_region.update_traces(marker_color='#FF8C00')
            st.plotly_chart(fig_bar_region, use_container_width=True)

    st.divider()

    # -----------------------------------------------------------
    # [Regional Expansion Strategy]
    # -----------------------------------------------------------
    st.subheader("ğŸ—ºï¸ ì§€ì—­ í™•ì¥ ì „ëµ (Regional Expansion Strategy)")
    
    if 'ê´‘ì—­ì§€ì—­' in df_filtered.columns:
        # 1. Target Region Selector
        all_regions = df_filtered['ê´‘ì—­ì§€ì—­'].unique().tolist()
        # Default to the region with highest sales if available, else standard sort
        default_region = region_stats.iloc[-1]['ê´‘ì—­ì§€ì—­'] if not region_stats.empty else all_regions[0]
        
        target_region = st.selectbox(
            "ê³µëµí•  ì§€ì—­ì„ ì„ íƒí•˜ì„¸ìš”",
            all_regions,
            index=all_regions.index(default_region) if default_region in all_regions else 0
        )
        
        # Filter for Target Region
        region_df = df_filtered[df_filtered['ê´‘ì—­ì§€ì—­'] == target_region]
        
        if not region_df.empty:
            # Expert Analysis Data Prep
            total_sales_all = df_filtered['ì‹¤ê²°ì œ ê¸ˆì•¡'].sum()
            current_region_sales = region_df['ì‹¤ê²°ì œ ê¸ˆì•¡'].sum()
            region_share = current_region_sales / total_sales_all if total_sales_all > 0 else 0
            
            # 1. Market Classification
            if region_share >= 0.10: # ì ìœ ìœ¨ 10% ì´ìƒì€ í•µì‹¬ ì§€ì—­
                region_type = "ğŸ‘‘ í•µì‹¬ ê±°ì  (Core Market)"
                strategy_focus = "ì¶©ì„±ë„ ê°•í™” & ê°ë‹¨ê°€ ìƒìŠ¹ (Lock-in & Up-sell)"
                growth_rate = 0.15 # ì´ë¯¸ ì„±ìˆ™í•œ ì‹œì¥ì€ ëª©í‘œ ì„±ì¥ë¥ ì„ ì¡°ê¸ˆ ë‚®ê²Œ ì¡ìŒ
            else:
                region_type = "ğŸŒ± ì„±ì¥ ì ì¬ ì§€ì—­ (Growth Market)"
                strategy_focus = "ì‹ ê·œ ê³ ê° í™•ë³´ & ì¸ì§€ë„ í™•ëŒ€ (Acquisition)"
                growth_rate = 0.30 # ì„±ì¥ ì´ˆê¸° ì§€ì—­ì€ ê³µê²©ì ì¸ ëª©í‘œ ì„¤ì •

            # 2. Demographics & Channel
            dominant_age = region_df['ì—°ë ¹ëŒ€'].value_counts().idxmax() if 'ì—°ë ¹ëŒ€' in region_df.columns else "ì•Œ ìˆ˜ ì—†ìŒ"
            dominant_channel = region_df['ì£¼ë¬¸ê²½ë¡œ'].value_counts().idxmax()

            # 3. Top Products & Revenue Projection
            top3_products = region_df.groupby('ìƒí’ˆëª…')['ì‹¤ê²°ì œ ê¸ˆì•¡'].sum().nlargest(3).reset_index()
            potential_sales = current_region_sales * (1 + growth_rate)
            upside = potential_sales - current_region_sales
            
            # UI Layout
            strat_col1, strat_col2 = st.columns([1, 2])
            
            with strat_col1:
                st.markdown(f"#### ğŸ“Š ì§€ì—­ ìœ„ìƒ ë° ëª©í‘œ")
                st.info(f"**{region_type}**\n\në§¤ì¶œ ë¹„ì¤‘: **{region_share*100:.1f}%**")
                
                st.metric(
                    "í˜„ì¬ ë§¤ì¶œ", 
                    f"{current_region_sales:,.0f} ì›"
                )
                st.metric(
                    f"ëª©í‘œ ë§¤ì¶œ (+{growth_rate*100:.0f}%)",
                    f"{potential_sales:,.0f} ì›",
                    delta=f"+{upside:,.0f} ì›"
                )
            
            with strat_col2:
                st.markdown(f"#### ì „ëµ ë¦¬í¬íŠ¸")
                st.caption(f"ğŸ¯ íƒ€ê²Ÿ í˜ë¥´ì†Œë‚˜: **{dominant_age}** | ğŸ“¢ ìµœì  ì±„ë„: **{dominant_channel}**")
                
                # Dynamic Recommendations
                st.markdown(f"**ì „ëµ ì´ˆì : {strategy_focus}**")
                
                rec_list = []
                top_prod_name = top3_products.iloc[0]['ìƒí’ˆëª…']
                
                if "í•µì‹¬" in region_type:
                    rec_list.append(f"**VIP ë§ˆì¼€íŒ…**: {target_region} ë‚´ êµ¬ë§¤ ì´ë ¥ ë³´ìœ  ê³ ê°ì—ê²Œ **ì‹œí¬ë¦¿ ì¿ í°** ë°œì†¡ (ì¬êµ¬ë§¤ ìœ ë„)")
                    rec_list.append(f"**ë²ˆë“¤ë§ ê°•í™”**: 1ìœ„ ìƒí’ˆì¸ '{top_prod_name}' êµ¬ë§¤ ì‹œ, ë‹¤ë¥¸ ìƒí’ˆ í•©ë°°ì†¡ í• ì¸ ì œì•ˆ (ê°ë‹¨ê°€ UP)")
                    rec_list.append(f"**ì±„ë„ ìµœì í™”**: {dominant_channel} ì±„ë„ì˜ ì¶©ì„± ê³ ê° ëŒ€ìƒìœ¼ë¡œ ë©¤ë²„ì‹­ í˜œíƒ í˜¹ì€ ì •ê¸° ë°°ì†¡ ì•ˆë‚´")
                else:
                    rec_list.append(f"**ê³µê²©ì  ì¹¨íˆ¬**: {dominant_channel} ê´‘ê³  ì˜ˆì‚°ì„ {target_region} ì§€ì—­ì— ì§‘ì¤‘ ì§‘í–‰")
                    rec_list.append(f"**ë¯¸ë¼ ìƒí’ˆ ì „ëµ**: '{top_prod_name}'ì˜ ì†Œìš©ëŸ‰/ì²´í—˜íŒ©ì„ ê¸°íší•˜ì—¬ ì§„ì… ì¥ë²½ ë‚®ì¶”ê¸°")
                    rec_list.append(f"**ë¡œì»¬ íƒ€ê²ŸíŒ…**: {target_region} ë§˜ì¹´í˜/ì»¤ë®¤ë‹ˆí‹° ì œíœ´ë¥¼ í†µí•´ '{target_region} í•œì • ë¬´ë£Œ ë°°ì†¡' ì´ë²¤íŠ¸ í™ë³´")

                for i, rec in enumerate(rec_list, 1):
                    st.write(f"{i}. {rec}")
                    
                st.markdown("---")
                st.write(f"**ğŸ† {target_region} Best 3**")
                cols = st.columns(3)
                for idx, row in top3_products.iterrows():
                    with cols[idx]:
                        st.caption(f"{idx+1}ìœ„")
                        st.write(f"**{row['ìƒí’ˆëª…']}**")
                        st.caption(f"{row['ì‹¤ê²°ì œ ê¸ˆì•¡']:,.0f}ì›")

            st.markdown("---")
            
            # [Age Group Strategy Analysis]
            st.subheader(f"ğŸ‘¥ {target_region} ì—°ë ¹ë³„ ê³µëµ ì „ëµ")
            
            if 'ì—°ë ¹ëŒ€' in region_df.columns:
                # 1. Age Distribution Chart
                age_dist = region_df.groupby('ì—°ë ¹ëŒ€')['ì‹¤ê²°ì œ ê¸ˆì•¡'].sum().reset_index()
                
                age_col1, age_col2 = st.columns([1, 1])
                
                with age_col1:
                     fig_age_donut = px.pie(
                        age_dist, 
                        values='ì‹¤ê²°ì œ ê¸ˆì•¡', 
                        names='ì—°ë ¹ëŒ€', 
                        hole=0.4,
                        title=f"{target_region} ì—°ë ¹ë³„ ë§¤ì¶œ ë¹„ì¤‘",
                        color_discrete_sequence=px.colors.sequential.Oranges
                    )
                     st.plotly_chart(fig_age_donut, use_container_width=True)
                
                with age_col2:
                    # 2. Dominant Age & Tactics
                    st.markdown(f"#### ğŸ¯ í•µì‹¬ íƒ€ê²Ÿ: {dominant_age}")
                    
                    tactics = {
                        "20ëŒ€": "ğŸ“± **ì¸ìŠ¤íƒ€/TikTok ìˆí¼ ë§ˆì¼€íŒ…**: 'ê°ì„± íŒ¨í‚¤ì§€'ì™€ 'ê°€ì„±ë¹„ ëª»ë‚œì´ ê³¼ì¼' ì†Œêµ¬ í¬ì¸íŠ¸ ê°•ì¡°",
                        "30ëŒ€": "ğŸ¢ **ì§ì¥ì¸/ìœ¡ì•„ë§˜ íƒ€ê²Ÿ**: 'ì•„ì´ ê°„ì‹', 'ì‚¬ë¬´ì‹¤ ê³µë™êµ¬ë§¤' í‚¤ì›Œë“œë¡œ ë§˜ì¹´í˜ ë° ë‹¹ê·¼ë§ˆì¼“ ê´‘ê³ ",
                        "40ëŒ€": "ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ **ê°€ì¡± ê±´ê°•/ì„ ë¬¼**: 'ë¶€ëª¨ë‹˜ ì„ ë¬¼', 'ì œì²  ë³´ì–‘' ë©”ì‹œì§€ë¡œ ë°´ë“œ(BAND) ë° ì¹´ì¹´ì˜¤í†¡ ì„ ë¬¼í•˜ê¸° ìœ ë„",
                        "50ëŒ€": "ğŸ”ï¸ **ë™í˜¸íšŒ/ì»¤ë®¤ë‹ˆí‹°**: ë“±ì‚°/ê³¨í”„ ë™í˜¸íšŒ ì œíœ´ ë° 'ë‹¨ì²´ ì£¼ë¬¸ í• ì¸' í”„ë¡œëª¨ì…˜ ì „ê°œ",
                        "60ëŒ€ ì´ìƒ": "ğŸ“ **ì „í™” ì£¼ë¬¸/ì§€ì¸ ì¶”ì²œ**: ê°€ë…ì„± ì¢‹ì€ ì´ë¯¸ì§€ ë¬¸ìì™€ ì „í™” ì£¼ë¬¸ ì „ìš© í•«ë¼ì¸ ìš´ì˜"
                    }
                    
                    selected_tactic = tactics.get(dominant_age, "ëª¨ë“  ì—°ë ¹ì¸µì„ ì•„ìš°ë¥´ëŠ” ëŒ€ì¤‘ì ì¸ ë§ˆì¼€íŒ… ì „ê°œ")
                    
                    st.info(f"**ğŸ’¡ {dominant_age} ë§ì¶¤ ê³µëµë²•**\n\n{selected_tactic}")
                    
                    # Show Top Product for this Age Group in this Region
                    age_specific_df = region_df[region_df['ì—°ë ¹ëŒ€'] == dominant_age]
                    if not age_specific_df.empty:
                        top_age_prod = age_specific_df.groupby('ìƒí’ˆëª…')['ì‹¤ê²°ì œ ê¸ˆì•¡'].sum().idxmax()
                        st.success(f"ğŸ”¥ **{dominant_age} ìµœë‹¤ êµ¬ë§¤ ìƒí’ˆ**: {top_age_prod}")
            else:
                st.info("ì—°ë ¹ëŒ€ ë°ì´í„°ê°€ ì—†ì–´ ìƒì„¸ ì „ëµì„ ìˆ˜ë¦½í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        else:
            st.warning(f"ì„ íƒí•œ ì§€ì—­({target_region})ì˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    st.divider()
    st.subheader("ğŸ•°ï¸ ì£¼ë¬¸ íŒ¨í„´ ë¶„ì„ (ì‹œê°„ëŒ€/ìš”ì¼)")
    
    if not df_filtered.empty:
        # Preprocessing for Heatmap
        # Ensure 'ìš”ì¼' is ordered correctly
        day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
        # Korean mapping if needed, but assuming data might have English or mixed. 
        # Let's check unique values or just use as is if already Korean. 
        # If 'ìš”ì¼' is already Korean (ì›”, í™”...), day_order needs to match.
        # Check if Sample data uses Korean days based on previous view_file (line 117: dt.day_name() returns English by default unless locale set, but let's stick to observed data or handle gracefully)
        
        # Safe aggregation
        heatmap_data = df_filtered.groupby(['ìš”ì¼', 'ì£¼ë¬¸ì‹œê°„'])['ì£¼ë¬¸ìˆ˜ëŸ‰'].sum().reset_index()
        
        # 1. Density Heatmap
        fig_heatmap = px.density_heatmap(
            heatmap_data, 
            x='ì£¼ë¬¸ì‹œê°„', 
            y='ìš”ì¼', 
            z='ì£¼ë¬¸ìˆ˜ëŸ‰', 
            nbinsx=24,
            category_orders={"ìš”ì¼": ["Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"] 
                             if heatmap_data['ìš”ì¼'].iloc[0] in ['Monday', 'Tuesday'] else 
                             ["ì›”ìš”ì¼", "í™”ìš”ì¼", "ìˆ˜ìš”ì¼", "ëª©ìš”ì¼", "ê¸ˆìš”ì¼", "í† ìš”ì¼", "ì¼ìš”ì¼"]},
            color_continuous_scale='OrRd',
            title="ìš”ì¼ x ì‹œê°„ëŒ€ë³„ ì£¼ë¬¸ ì§‘ì¤‘ë„ (Heatmap)"
        )
        fig_heatmap.update_layout(xaxis_title="ì‹œê°„ëŒ€ (0~23ì‹œ)", yaxis_title="ìš”ì¼")
        st.plotly_chart(fig_heatmap, use_container_width=True)
        
        # 2. Peak Time Analysis
        heatmap_data['Hotscore'] = heatmap_data['ì£¼ë¬¸ìˆ˜ëŸ‰']
        top_slots = heatmap_data.sort_values('Hotscore', ascending=False).head(3)
        
        if not top_slots.empty:
            st.markdown("#### âš¡ ê³¨ë“  íƒ€ì„ (Golden Hours)")
            
            c1, c2, c3 = st.columns(3)
            for i, (idx, row) in enumerate(top_slots.iterrows()):
                with [c1, c2, c3][i]:
                    st.metric(
                        f"Top {i+1}", 
                        f"{row['ìš”ì¼']} {row['ì£¼ë¬¸ì‹œê°„']}ì‹œ", 
                        f"{row['ì£¼ë¬¸ìˆ˜ëŸ‰']}ê±´ ì£¼ë¬¸"
                    )
            
            # 3. Actionable Advice
            best_day = top_slots.iloc[0]['ìš”ì¼']
            best_hour = top_slots.iloc[0]['ì£¼ë¬¸ì‹œê°„']
            
            # Simple logic for advice
            target_hour = best_hour - 1 if best_hour > 0 else 23
            
            st.info(f"""
            **ğŸ“¢ ë§ˆì¼€íŒ… ê³¨ë“  íƒ€ì„ ì œì•ˆ**
            
            ê°€ì¥ ì£¼ë¬¸ì´ ë§ì€ **{best_day} {best_hour}ì‹œ**ë¥¼ ê³µëµí•˜ì„¸ìš”!
            - **PUSH ì•Œë¦¼**: 1ì‹œê°„ ì „ì¸ **{best_day} {target_hour}ì‹œ**ì— í• ì¸ ì¿ í°ì´ë‚˜ íƒ€ì„ ì„¸ì¼ ì•Œë¦¼ì„ ë³´ë‚´ë©´ ì „í™˜ìœ¨ì´ ê·¹ëŒ€í™”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
            - **ê´‘ê³  ì…ì°°ê°€ ìƒí–¥**: ì´ ì‹œê°„ëŒ€ì— ê²€ìƒ‰ ê´‘ê³  ì…ì°°ê°€ë¥¼ **20~30% ìƒí–¥** ì¡°ì •í•˜ì—¬ ë…¸ì¶œì„ ëŠ˜ë¦¬ì„¸ìš”.
            """)
    else:
        st.warning("ë°ì´í„°ê°€ ì—†ì–´ ì£¼ë¬¸ íŒ¨í„´ì„ ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

elif "ê³ ê°" in menu:
    # [View 4] ğŸ‘¥ ê³ ê° ë¶„ì„ Analysis (Comprehensive)
    st.header("ğŸ‘¥ ê³ ê° ë°ì´í„° ë¶„ì„ (Customer Intelligence)")

    if not df_filtered.empty:
        max_date = df_filtered['ì£¼ë¬¸ì¼'].max()
        
        # Tabs for organized view
        tab1, tab2, tab3 = st.tabs(["ğŸ“Š ê¸°ë³¸ ë¶„ì„ (Basic)", "ğŸ’ ê³ ê¸‰ ë¶„ì„ (VIP/Retention)", "âœ¨ ì‹¬ì¸µ ì¸ì‚¬ì´íŠ¸ (Deep Dive)"])
        
        # --- Tab 1: Basic Analysis (Restored) ---
        with tab1:
            st.subheader("ğŸ”„ ì¬êµ¬ë§¤ìœ¨ ë° ì¸êµ¬í†µê³„ ë¶„ì„")
            
            # 1. Repurchase Rate
            if 'ì¬êµ¬ë§¤ íšŸìˆ˜' in df_filtered.columns and 'UID' in df_filtered.columns:
                cust_stats = df_filtered.groupby('UID')['ì¬êµ¬ë§¤ íšŸìˆ˜'].max().reset_index()
                total_customers = len(cust_stats)
                returning_customers = len(cust_stats[cust_stats['ì¬êµ¬ë§¤ íšŸìˆ˜'] > 0])
                repurchase_rate = (returning_customers / total_customers * 100) if total_customers > 0 else 0
                
                c1, c2, c3 = st.columns(3)
                c1.metric("ì „ì²´ ê³ ê°", f"{total_customers:,}ëª…")
                c2.metric("ì¬êµ¬ë§¤ ê³ ê°", f"{returning_customers:,}ëª…")
                c3.metric("ì¬êµ¬ë§¤ìœ¨", f"{repurchase_rate:.1f}%")
                
                col_chart1, col_chart2 = st.columns(2)
                with col_chart1:
                    vals = [total_customers - returning_customers, returning_customers]
                    fig_pie = px.pie(
                        values=vals, 
                        names=['ì‹ ê·œ (1íšŒ)', 'ì¬êµ¬ë§¤ (2íšŒ+)'], 
                        hole=0.4, 
                        title="ì‹ ê·œ vs ì¬êµ¬ë§¤ ë¹„ìœ¨",
                        color_discrete_sequence=['#E0E0E0', '#FF7F50']
                    )
                    st.plotly_chart(fig_pie, use_container_width=True)
                with col_chart2:
                    st.info("ğŸ’¡ **ì¬êµ¬ë§¤ ìœ ë„ íŒ**\n\nì¬êµ¬ë§¤ìœ¨ì´ 30% ë¯¸ë§Œì´ë¼ë©´ 'ì²« êµ¬ë§¤ ê°ì‚¬ ì¿ í°' ë°œì†¡ì„ ìë™í™”í•´ë³´ì„¸ìš”.")

            st.divider()

            # 2. Age & Gender (if available)
            if 'ì—°ë ¹ëŒ€' in df_filtered.columns:
                col_age1, col_age2 = st.columns(2)
                with col_age1:
                    age_sales = df_filtered.groupby('ì—°ë ¹ëŒ€')['ì‹¤ê²°ì œ ê¸ˆì•¡'].sum().reset_index()
                    fig_age = px.pie(age_sales, values='ì‹¤ê²°ì œ ê¸ˆì•¡', names='ì—°ë ¹ëŒ€', title="ì—°ë ¹ë³„ ë§¤ì¶œ ë¹„ì¤‘", hole=0.4)
                    st.plotly_chart(fig_age, use_container_width=True)
                with col_age2:
                    age_aov = df_filtered.groupby('ì—°ë ¹ëŒ€')['ì‹¤ê²°ì œ ê¸ˆì•¡'].mean().reset_index()
                    fig_aov = px.bar(age_aov, x='ì—°ë ¹ëŒ€', y='ì‹¤ê²°ì œ ê¸ˆì•¡', title="ì—°ë ¹ë³„ ê°ë‹¨ê°€ ë¹„êµ", color='ì‹¤ê²°ì œ ê¸ˆì•¡')
                    st.plotly_chart(fig_aov, use_container_width=True)
            else:
                st.warning("ì—°ë ¹ëŒ€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

        # --- Tab 2: Advanced Analysis (RFM & Cohort) ---
        with tab2:
            # 1. RFM Segmentation
            st.subheader("ğŸ’ RFM ê³ ê° ì„¸ë¶„í™”")
            
            rfm = df_filtered.groupby('UID').agg({
                'ì£¼ë¬¸ì¼': lambda x: (max_date - x.max()).days, # Recency
                'ì£¼ë¬¸ë²ˆí˜¸': 'count', # Frequency
                'ì‹¤ê²°ì œ ê¸ˆì•¡': 'sum' # Monetary
            }).reset_index()
            rfm.rename(columns={'ì£¼ë¬¸ì¼': 'Recency', 'ì£¼ë¬¸ë²ˆí˜¸': 'Frequency', 'ì‹¤ê²°ì œ ê¸ˆì•¡': 'Monetary'}, inplace=True)
            
            def assign_rfm_segment(row):
                if row['Recency'] > 90:
                    if row['Monetary'] > 200000: return 'ì´íƒˆ ìš°ë ¤ (VIP)'
                    else: return 'ì´íƒˆ ê³ ê° (Lost)'
                else:
                    if row['Monetary'] > 300000: return 'VIP (ìµœìƒìœ„)'
                    elif row['Frequency'] >= 3: return 'ì¶©ì„± ê³ ê° (Loyal)'
                    elif row['Recency'] <= 30: return 'ì‹ ê·œ/ìµœê·¼ (New)'
                    else: return 'ì¼ë°˜ (Regular)'

            rfm['Segment'] = rfm.apply(assign_rfm_segment, axis=1)
            
            col_rfm1, col_rfm2 = st.columns([1, 1])
            with col_rfm1:
                seg_counts = rfm['Segment'].value_counts().reset_index()
                seg_counts.columns = ['Segment', 'Count']
                fig_rfm = px.pie(seg_counts, values='Count', names='Segment', title="ê³ ê° ë“±ê¸‰ë³„ ë¹„ì¤‘", hole=0.4)
                st.plotly_chart(fig_rfm, use_container_width=True)
            with col_rfm2:
                st.markdown("#### ğŸ“¢ ë“±ê¸‰ë³„ ê´€ë¦¬ ì „ëµ")
                st.info("""
                - **ğŸ’ VIP**: ì „ìš© í•«ë¼ì¸ ë° ì‹œí¬ë¦¿ ì¿ í° ì œê³µ
                - **ğŸ’– ì¶©ì„±**: ì •ê¸° êµ¬ë… ì„œë¹„ìŠ¤ ì œì•ˆ
                - **ğŸŒ± ì‹ ê·œ**: 'në²ˆì§¸ êµ¬ë§¤' ë‹¬ì„± í”„ë¡œëª¨ì…˜
                - **âš ï¸ ì´íƒˆ**: ì›°ì»´ë°± ì¿ í° ìë™ ë°œì†¡
                """)

            st.divider()

            # 2. Cohort Analysis
            st.subheader("ğŸ“… ì½”í˜¸íŠ¸ ì”ì¡´ìœ¨ (Cohort Retention)")
            df_filtered['OrderMonth'] = df_filtered['ì£¼ë¬¸ì¼'].dt.to_period('M')
            df_filtered['CohortMonth'] = df_filtered.groupby('UID')['ì£¼ë¬¸ì¼'].transform('min').dt.to_period('M')
            
            cohort_data = df_filtered.groupby(['CohortMonth', 'OrderMonth'])['UID'].nunique().reset_index()
            cohort_data['Period'] = (cohort_data['OrderMonth'] - cohort_data['CohortMonth']).apply(lambda x: x.n)
            
            cohort_pivot = cohort_data.pivot_table(index='CohortMonth', columns='Period', values='UID')
            cohort_size = cohort_pivot.iloc[:, 0]
            retention = cohort_pivot.divide(cohort_size, axis=0)
            
            fig_cohort = px.imshow(
                retention,
                labels=dict(x="ê²½ê³¼ ê°œì›” ìˆ˜", y="ê°€ì… ì›”", color="ì”ì¡´ìœ¨"),
                x=retention.columns,
                y=retention.index.astype(str),
                color_continuous_scale='Blues',
                text_auto='.1%'
            )
            st.plotly_chart(fig_cohort, use_container_width=True)

        # --- Tab 3: Additional Insights (New) ---
        with tab3:
            st.subheader("âœ¨ 3ê°€ì§€ ì¶”ê°€ ì¸ì‚¬ì´íŠ¸ (Deep Dive)")
            
            # Insight 1: Geo-Distribution
            st.markdown("##### 1. ğŸ“ ì§€ì—­ë³„ ê³ ê° ë¶„í¬ (Top Regions)")
            if 'ì§€ì—­' in df_filtered.columns:
                geo_dist = df_filtered.groupby('ì§€ì—­')['UID'].nunique().reset_index().sort_values('UID', ascending=False).head(10)
                fig_geo = px.bar(geo_dist, x='ì§€ì—­', y='UID', title="ì§€ì—­ë³„ ê³ ê° ìˆ˜ Top 10", color='UID', color_continuous_scale='Viridis')
                st.plotly_chart(fig_geo, use_container_width=True)
            else:
                st.info("ì§€ì—­ ë°ì´í„°ê°€ ì—†ì–´ ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                
            st.divider()

            # Insight 2: Purchase Time Pattern (VIP vs Regular)
            st.markdown("##### 2. â° VIP ê³ ê°ì˜ ì£¼ êµ¬ë§¤ ì‹œê°„ëŒ€")
            df_filtered['Hour'] = df_filtered['ì£¼ë¬¸ì¼'].dt.hour
            
            # Join segment info back to main df
            rfm_map = rfm[['UID', 'Segment']]
            df_seg = df_filtered.merge(rfm_map, on='UID', how='left')
            
            vip_hourly = df_seg[df_seg['Segment'].str.contains('VIP')].groupby('Hour')['ì£¼ë¬¸ë²ˆí˜¸'].count().reset_index()
            reg_hourly = df_seg[~df_seg['Segment'].str.contains('VIP')].groupby('Hour')['ì£¼ë¬¸ë²ˆí˜¸'].count().reset_index()
            
            fig_time = go.Figure()
            fig_time.add_trace(go.Scatter(x=vip_hourly['Hour'], y=vip_hourly['ì£¼ë¬¸ë²ˆí˜¸'], mode='lines+markers', name='VIP ê³ ê°', line=dict(color='gold', width=3)))
            fig_time.add_trace(go.Scatter(x=reg_hourly['Hour'], y=reg_hourly['ì£¼ë¬¸ë²ˆí˜¸'], mode='lines', name='ì¼ë°˜ ê³ ê°', line=dict(color='grey', dash='dot')))
            fig_time.update_layout(title="ì‹œê°„ëŒ€ë³„ ì£¼ë¬¸ íŒ¨í„´ ë¹„êµ (VIP vs ì¼ë°˜)", xaxis_title="ì‹œê°„ (0~23ì‹œ)", yaxis_title="ì£¼ë¬¸ ê±´ìˆ˜")
            st.plotly_chart(fig_time, use_container_width=True)
            st.caption("* VIP ê³ ê°ì´ í™œë™í•˜ëŠ” ê³¨ë“  íƒ€ì„ì„ íŒŒì•…í•˜ì—¬ íƒ€ì„ë”œì„ ê¸°íší•˜ì„¸ìš”.")
            
            st.divider()

            # Insight 3: Category Preference
            st.markdown("##### 3. ğŸ›ï¸ VIP ì„ í˜¸ ì¹´í…Œê³ ë¦¬ (Category Preference)")
            # Assuming 'ì¹´í…Œê³ ë¦¬' column exists, or use 'ìƒí’ˆëª…' top keywords if not
            target_col = 'ì¹´í…Œê³ ë¦¬' if 'ì¹´í…Œê³ ë¦¬' in df_filtered.columns else 'ìƒí’ˆëª…'
            
            vip_pref = df_seg[df_seg['Segment'].str.contains('VIP')][target_col].value_counts().head(5).reset_index()
            vip_pref.columns = [target_col, 'Count']
            
            fig_cat = px.bar(vip_pref, x='Count', y=target_col, orientation='h', title=f"VIP ê³ ê°ì´ ê°€ì¥ ë§ì´ ì‚° {target_col}", color='Count')
            st.plotly_chart(fig_cat, use_container_width=True)

    else:
        st.warning("ë¶„ì„í•  ê³ ê° ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

elif "ì…€ëŸ¬" in menu:
    # [View 5] ğŸ“ˆ ì…€ëŸ¬ ë¶„ì„ Analysis (Advanced)
    st.header("ğŸ“ˆ ì…€ëŸ¬ ì„±ê³¼ ë° ê´€ë¦¬ (Seller Management)")
    
    if not df_filtered.empty:
        # Pre-calc: Last Date in data
        max_date = df_filtered['ì£¼ë¬¸ì¼'].max()
        
        # 1. Seller Metrics Calculation
        seller_stats = df_filtered.groupby('ì…€ëŸ¬ëª…').agg({
            'ì‹¤ê²°ì œ ê¸ˆì•¡': 'sum',
            'ì£¼ë¬¸ìˆ˜ëŸ‰': 'sum',
            'ì£¼ë¬¸ë²ˆí˜¸': 'count', # Order Count
            'ì£¼ë¬¸ì¼': 'max' # Last Active
        }).reset_index()
        
        seller_stats.rename(columns={'ì£¼ë¬¸ë²ˆí˜¸': 'ì£¼ë¬¸ê±´ìˆ˜', 'ì£¼ë¬¸ì¼': 'ìµœê·¼í™œë™ì¼'}, inplace=True)
        seller_stats['ê°ë‹¨ê°€(AOV)'] = seller_stats['ì‹¤ê²°ì œ ê¸ˆì•¡'] / seller_stats['ì£¼ë¬¸ê±´ìˆ˜']
        
        # 2. Seller Segmentation (S/A/B Grade)
        seller_stats = seller_stats.sort_values('ì‹¤ê²°ì œ ê¸ˆì•¡', ascending=False)
        seller_stats['Cumulative Sales'] = seller_stats['ì‹¤ê²°ì œ ê¸ˆì•¡'].cumsum()
        seller_stats['Cumulative Perc'] = seller_stats['Cumulative Sales'] / seller_stats['ì‹¤ê²°ì œ ê¸ˆì•¡'].sum()
        
        def assign_seller_grade(row):
            if row['Cumulative Perc'] <= 0.10: return 'S (ìµœìƒìœ„)'
            elif row['Cumulative Perc'] <= 0.40: return 'A (ìš°ìˆ˜)'
            else: return 'B (ì¼ë°˜)'
            
        seller_stats['ë“±ê¸‰'] = seller_stats.apply(assign_seller_grade, axis=1)
        
        # 3. Growth Rate (Last 30 Days vs Previous 30 Days)
        t_current_start = max_date - timedelta(days=30)
        t_prev_start = t_current_start - timedelta(days=30)
        
        df_current = df_filtered[df_filtered['ì£¼ë¬¸ì¼'] >= t_current_start]
        df_prev = df_filtered[(df_filtered['ì£¼ë¬¸ì¼'] < t_current_start) & (df_filtered['ì£¼ë¬¸ì¼'] >= t_prev_start)]
        
        curr_sales = df_current.groupby('ì…€ëŸ¬ëª…')['ì‹¤ê²°ì œ ê¸ˆì•¡'].sum().reset_index().rename(columns={'ì‹¤ê²°ì œ ê¸ˆì•¡': 'CurrentSales'})
        prev_sales = df_prev.groupby('ì…€ëŸ¬ëª…')['ì‹¤ê²°ì œ ê¸ˆì•¡'].sum().reset_index().rename(columns={'ì‹¤ê²°ì œ ê¸ˆì•¡': 'PrevSales'})
        
        growth_df = curr_sales.merge(prev_sales, on='ì…€ëŸ¬ëª…', how='outer').fillna(0)
        growth_df['GrowthRate'] = ((growth_df['CurrentSales'] - growth_df['PrevSales']) / growth_df['PrevSales'].replace(0, 1)) * 100
        
        # Merge Growth into Stats
        seller_stats = seller_stats.merge(growth_df[['ì…€ëŸ¬ëª…', 'GrowthRate']], on='ì…€ëŸ¬ëª…', how='left').fillna(0)

        # 4. Churn Risk (Dormant > 30 Days)
        seller_stats['DaysSinceActive'] = (max_date - seller_stats['ìµœê·¼í™œë™ì¼']).dt.days
        seller_stats['Status'] = seller_stats['DaysSinceActive'].apply(lambda x: 'âš ï¸ íœ´ë©´ ìœ„í—˜' if x >= 30 else 'âœ… í™œë™ ì¤‘')
        
        # --- UI Rendering ---
        
        # Summary Metrics
        st.subheader("ğŸ“Š ì…€ëŸ¬ í˜„í™© ê°œìš”")
        col_s1, col_s2, col_s3, col_s4 = st.columns(4)
        
        with col_s1:
            st.metric("ì´ í™œë™ ì…€ëŸ¬", f"{len(seller_stats)}ëª…")
        with col_s2:
            s_grade_count = len(seller_stats[seller_stats['ë“±ê¸‰'].str.contains('S')])
            st.metric("Së“±ê¸‰(ìƒìœ„ 10%)", f"{s_grade_count}ëª…")
        with col_s3:
            rising_stars = len(seller_stats[seller_stats['GrowthRate'] >= 20])
            st.metric("ê¸‰ì„±ì¥ ì…€ëŸ¬ (MoM +20%â†‘)", f"{rising_stars}ëª…")
        with col_s4:
            churn_risk = len(seller_stats[seller_stats['Status'].str.contains('ìœ„í—˜')])
            st.metric("ì´íƒˆ ìœ„í—˜ (30ì¼ ë¬´ì‹¤ì )", f"{churn_risk}ëª…", delta=-churn_risk, delta_color="inverse")

        st.divider()

        col_main1, col_main2 = st.columns([1, 1])
        
        with col_main1:
            st.markdown("##### ğŸš€ ë¼ì´ì§• ìŠ¤íƒ€ (Top Growth)")
            # Filter: Min 10 orders to avoid noise
            rising_df = seller_stats[seller_stats['ì£¼ë¬¸ê±´ìˆ˜'] >= 10].sort_values('GrowthRate', ascending=False).head(5)
            if not rising_df.empty:
                st.dataframe(
                    rising_df[['ë“±ê¸‰', 'ì…€ëŸ¬ëª…', 'GrowthRate', 'ì‹¤ê²°ì œ ê¸ˆì•¡']].style.format({
                        'GrowthRate': "{:+.1f}%", 
                        'ì‹¤ê²°ì œ ê¸ˆì•¡': "{:,.0f}"
                    }),
                    use_container_width=True, hide_index=True
                )
            else:
                st.info("ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ì„±ì¥ ì…€ëŸ¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
                
        with col_main2:
             st.markdown("##### âš ï¸ ì´íƒˆ ìœ„í—˜êµ° (Dormant)")
             dormant_df = seller_stats[seller_stats['Status'].str.contains('ìœ„í—˜')].sort_values('DaysSinceActive', ascending=False).head(5)
             if not dormant_df.empty:
                 st.dataframe(
                    dormant_df[['ë“±ê¸‰', 'ì…€ëŸ¬ëª…', 'ìµœê·¼í™œë™ì¼', 'DaysSinceActive']],
                    use_container_width=True, hide_index=True
                )
             else:
                 st.success("ìµœê·¼ 30ì¼ ì´ë‚´ í™œë™í•˜ì§€ ì•Šì€ ì…€ëŸ¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        st.divider()

        # [Restored] 5. Monthly Seller Inflow & Churn Trend
        st.subheader("ğŸ“† ì›”ë³„ ì…€ëŸ¬ ìœ ì…/ì´íƒˆ ì¶”ì´")
        
        # Inflow Logic (First Order Date)
        first_dates = df_filtered.groupby('ì…€ëŸ¬ëª…')['ì£¼ë¬¸ì¼'].min().reset_index()
        first_dates['Month'] = first_dates['ì£¼ë¬¸ì¼'].dt.to_period('M').astype(str)
        new_counts = first_dates.groupby('Month')['ì…€ëŸ¬ëª…'].count().reset_index()
        
        fig_inflow = px.bar(
            new_counts, 
            x='Month', 
            y='ì…€ëŸ¬ëª…', 
            title="ì›”ë³„ ì‹ ê·œ ì…€ëŸ¬ ìœ ì… ìˆ˜ (New Sellers)", 
            labels={'ì…€ëŸ¬ëª…': 'ì‹ ê·œ ì…€ëŸ¬ ìˆ˜', 'Month': 'ì›”'},
            color_discrete_sequence=['#2ECC71']
        )
        st.plotly_chart(fig_inflow, use_container_width=True)
        
        # 6. Strategic Insights (Sales & Acquisition)
        st.divider()
        st.subheader("ğŸ’¡ ì…€ëŸ¬ ì„±ì¥ ë° í™•ë³´ ì „ëµ (Strategy Report)")
        
        strat_col1, strat_col2 = st.columns(2)
        
        with strat_col1:
            st.markdown("#### ğŸŒ± ë“±ê¸‰ë³„ íŒë§¤ ì¦ëŒ€ ê°€ì´ë“œ")
            st.info("""
            **ğŸ‘‘ Së“±ê¸‰ (ìƒìœ„ 10% - ì„ ë„ ê·¸ë£¹)**
            - **ì „ëµ**: `ë¸Œëœë“œ íŒ¬ë¤ êµ¬ì¶•` ë° `ê°ë‹¨ê°€(AOV) ê·¹ëŒ€í™”`
            - **ì•¡ì…˜**: í”„ë¦¬ë¯¸ì—„ ë¼ì¸ì—… ë‹¨ë… ê¸°íšì „, VIP ì „ìš© 'ì„ ë¬¼í•˜ê¸°' íŒ¨í‚¤ì§€ ê°œë°œì§€ì›
            
            **ğŸš€ Aë“±ê¸‰ (ìƒìœ„ 30% - ì„±ì¥ ê·¸ë£¹)**
            - **ì „ëµ**: `êµ¬ë§¤ ì „í™˜ìœ¨ ê°œì„ ` ë° `ì¬êµ¬ë§¤ ìœ ë„`
            - **ì•¡ì…˜**: ë² ìŠ¤íŠ¸ ìƒí’ˆ ë¦¬ë·° ì´ë²¤íŠ¸, 'ì²« êµ¬ë§¤ í›„ 1ê°œì›” ë‚´ ì¬êµ¬ë§¤' ì¿ í° ë°œì†¡ ìë™í™”
            
            **ğŸŒ± Bë“±ê¸‰ (ì¼ë°˜ - ìœ¡ì„± ê·¸ë£¹)**
            - **ì „ëµ**: `ìƒí’ˆ ë…¸ì¶œ í™•ëŒ€` ë° `ê¸°ì´ˆ ì„¸íŒ… ìµœì í™”`
            - **ì•¡ì…˜**: ì¸ë„¤ì¼/ìƒì„¸í˜ì´ì§€ ë¬´ë£Œ ì§„ë‹¨ ì»¨ì„¤íŒ…, ê²€ìƒ‰ê´‘ê³ (CPC) ì†Œì•¡ ì§€ì› í”„ë¡œëª¨ì…˜
            """)
            
        with strat_col2:
            st.markdown("#### ğŸ“¢ ì‹ ê·œ ì…€ëŸ¬ í™•ë³´(Acquisition) ì „ìˆ ")
            
            # Analyze recent inflow trend
            recent_months = new_counts.sort_values('Month', ascending=False).head(2)
            if len(recent_months) >= 2:
                last_month_cnt = recent_months.iloc[0]['ì…€ëŸ¬ëª…']
                prev_month_cnt = recent_months.iloc[1]['ì…€ëŸ¬ëª…']
                
                if last_month_cnt < prev_month_cnt:
                   status_msg = f"ğŸ“‰ **ê²½ê³ **: ì§€ë‚œë‹¬ ëŒ€ë¹„ ì‹ ê·œ ìœ ì…ì´ ê°ì†Œí–ˆìŠµë‹ˆë‹¤. ({prev_month_cnt}ëª… â†’ {last_month_cnt}ëª…)"
                   action_msg = """
                   - **ì¶”ì²œì¸ ë³´ìƒ ê°•í™”**: ê¸°ì¡´ ì…€ëŸ¬ê°€ ì‹ ê·œ ì…€ëŸ¬ ì¶”ì²œ ì‹œ 'íŒë§¤ ìˆ˜ìˆ˜ë£Œ 1ê°œì›” ë©´ì œ' í˜œíƒ ì œê³µ
                   - **íŒŒì›Œë¸”ë¡œê±°/ìœ íŠœë²„ ì œíœ´**: 'ë†ì‚°ë¬¼ íŒë§¤ ì„±ê³µ ì‚¬ë¡€' ì½˜í…ì¸  ì œì‘ ë° ë°°í¬
                   """
                   st.warning(f"{status_msg}\n{action_msg}")
                else:
                   status_msg = f"ğŸ“ˆ **ì–‘í˜¸**: ì‹ ê·œ ìœ ì…ì´ ì¦ê°€í•˜ê±°ë‚˜ ìœ ì§€ë˜ê³  ìˆìŠµë‹ˆë‹¤. ({prev_month_cnt}ëª… â†’ {last_month_cnt}ëª…)"
                   action_msg = """
                   - **ì˜¨ë³´ë”© í”„ë¡œì„¸ìŠ¤ ìµœì í™”**: ê°€ì… í›„ ì²« ìƒí’ˆ ë“±ë¡ê¹Œì§€ ê±¸ë¦¬ëŠ” ì‹œê°„ì„ ë‹¨ì¶•ì‹œí‚¤ì„¸ìš”.
                   - **ì´ˆê¸° ì •ì°© ì§€ì›**: 'ì‹ ê·œ ì…ì  ì›°ì»´ í‚¤íŠ¸' (í¬ì¥ì¬ ìƒ˜í”Œ ë“±) ì œê³µìœ¼ë¡œ ì´íƒˆ ë°©ì§€
                   """
                   st.success(f"{status_msg}\n{action_msg}")
            else:
                st.info("ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ ìœ ì… ì¶”ì´ë¥¼ ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        st.divider()

        # 7. Market Basket Analysis (Bundle Strategies) [NEW/REPLACEMENT]
        st.subheader("ğŸ›’ ì¥ë°”êµ¬ë‹ˆ ë¶„ì„ (Market Basket Analysis)")
        st.markdown("ê³ ê°ì˜ **ë™ì‹œ êµ¬ë§¤ íŒ¨í„´**ì„ ë¶„ì„í•˜ì—¬ ê°ë‹¨ê°€(AOV)ë¥¼ ë†’ì¼ ìˆ˜ ìˆëŠ” **ê¿€ì¡°í•© ìƒí’ˆ**ì„ ì œì•ˆí•©ë‹ˆë‹¤.")
        
        if 'ì£¼ë¬¸ë²ˆí˜¸' in df_filtered.columns and 'ìƒí’ˆëª…' in df_filtered.columns:
            # 7-1. Single vs Multi-item Order Analysis
            order_counts = df_filtered.groupby('ì£¼ë¬¸ë²ˆí˜¸')['ìƒí’ˆëª…'].count()
            multi_item_orders = order_counts[order_counts > 1].index
            single_item_orders = order_counts[order_counts == 1].index
            
            multi_aov = df_filtered[df_filtered['ì£¼ë¬¸ë²ˆí˜¸'].isin(multi_item_orders)]['ì‹¤ê²°ì œ ê¸ˆì•¡'].sum() / len(multi_item_orders) if len(multi_item_orders) > 0 else 0
            single_aov = df_filtered[df_filtered['ì£¼ë¬¸ë²ˆí˜¸'].isin(single_item_orders)]['ì‹¤ê²°ì œ ê¸ˆì•¡'].sum() / len(single_item_orders) if len(single_item_orders) > 0 else 0
            
            c_b1, c_b2, c_b3 = st.columns(3)
            c_b1.metric("ë‹¨í’ˆ ì£¼ë¬¸ ë¹„ì¤‘", f"{(len(single_item_orders)/len(order_counts)*100):.1f}%")
            c_b2.metric("í•©ë°°ì†¡(ì„¸íŠ¸) ì£¼ë¬¸ ë¹„ì¤‘", f"{(len(multi_item_orders)/len(order_counts)*100):.1f}%")
            c_b3.metric("ì„¸íŠ¸ êµ¬ë§¤ì‹œ ê°ë‹¨ê°€ íš¨ê³¼", f"+{((multi_aov - single_aov)/single_aov*100):.1f}%", delta_color="normal")
            
            st.info(f"ğŸ’¡ ê³ ê°ì´ ìƒí’ˆì„ ë¬¶ì–´ ì‚´ ë•Œ, ë‹¨í’ˆ êµ¬ë§¤ë³´ë‹¤ ê°ë‹¨ê°€ê°€ ì•½ **{int(multi_aov - single_aov):,}ì›** ë” ë†’ìŠµë‹ˆë‹¤. ì„¸íŠ¸ ìƒí’ˆ êµ¬ì„±ì´ í•„ìˆ˜ì ì…ë‹ˆë‹¤.")
            
            # 7-2. Top Synergy Pairs (Co-occurrence)
            from itertools import combinations
            from collections import Counter
            
            # Get list of products per order (only for multi-item orders)
            # Optimization: Limit to top 1000 orders if too slow, but dataset seems small enough considering context
            multi_order_df = df_filtered[df_filtered['ì£¼ë¬¸ë²ˆí˜¸'].isin(multi_item_orders)]
            
            # Group items by order
            basket_lists = multi_order_df.groupby('ì£¼ë¬¸ë²ˆí˜¸')['ìƒí’ˆëª…'].apply(list)
            
            pair_counter = Counter()
            for items in basket_lists:
                items = sorted(items) # Sort to ensure (A, B) is same as (B, A)
                pair_counter.update(combinations(items, 2))
                
            top_pairs = pair_counter.most_common(5)
            
            st.markdown("##### ğŸ¤ í•¨ê»˜ ì‚¬ë©´ ì¢‹ì€ 'ê¿€ì¡°í•©' Top 5 (Synergy Pairs)")
            
            if top_pairs:
                pair_data = []
                for (item1, item2), count in top_pairs:
                    pair_data.append({
                        'ìƒí’ˆ A': item1,
                        'ìƒí’ˆ B': item2,
                        'ë™ì‹œ êµ¬ë§¤ íšŸìˆ˜': count,
                        'ì¶”ì²œ ì „ëµ': 'ë²ˆë“¤ í• ì¸ íŒ¨í‚¤ì§€ êµ¬ì„± (5~10% í• ì¸)'
                    })
                st.dataframe(pd.DataFrame(pair_data), use_container_width=True, hide_index=True)
            else:
                st.warning("ë™ì‹œ êµ¬ë§¤ ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•Šì•„ ì¡°í•©ì„ ì¶”ì²œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                
        else:
            st.warning("ì£¼ë¬¸ë²ˆí˜¸ ë˜ëŠ” ìƒí’ˆëª… ë°ì´í„°ê°€ ì—†ì–´ ì¥ë°”êµ¬ë‹ˆ ë¶„ì„ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        st.divider()
        
        # Detailed Table
        st.markdown("##### ğŸ“‹ ì „ì²´ ì…€ëŸ¬ ìƒì„¸ ì§€í‘œ")
        
        # Clean col names for display
        display_cols = ['ë“±ê¸‰', 'ì…€ëŸ¬ëª…', 'ì‹¤ê²°ì œ ê¸ˆì•¡', 'GrowthRate', 'ì£¼ë¬¸ê±´ìˆ˜', 'ê°ë‹¨ê°€(AOV)', 'ìµœê·¼í™œë™ì¼', 'Status']
        
        st.dataframe(
            seller_stats[display_cols].style.format({
                'ì‹¤ê²°ì œ ê¸ˆì•¡': "{:,.0f}",
                'GrowthRate': "{:+.1f}%",
                'ì£¼ë¬¸ê±´ìˆ˜': "{:,.0f}",
                'ê°ë‹¨ê°€(AOV)': "{:,.0f}"
            }),
            use_container_width=True,
            hide_index=True
        )
        
    else:
        st.warning("ë¶„ì„í•  ì…€ëŸ¬ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
